{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPpAOCObZwtfRir/spAViDE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Quick distribution check\n","import pandas as pd\n","\n","train = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/train_final_selected.parquet')\n","test = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/test.parquet')\n","\n","print(f\"Train shape: {train.shape}\")\n","print(f\"Test shape: {test.shape}\")\n","print(f\"Train date range: {train.index.min()} to {train.index.max()}\")\n","print(f\"Test date range: {test.index.min()} to {test.index.max()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otrfGXRFcaKZ","executionInfo":{"status":"ok","timestamp":1753394488990,"user_tz":-480,"elapsed":159647,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"78940d51-54b1-4a83-a7cf-7533fc3a3c1c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Train shape: (525886, 402)\n","Test shape: (538150, 786)\n","Train date range: 0 to 525885\n","Test date range: 1 to 538150\n"]}]},{"cell_type":"code","source":["# Quick drift detection on training data across time periods\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Load your training data\n","train = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/train_final_selected.parquet')\n","selected_features_df = pd.read_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/selected_features.csv')\n","final_features = selected_features_df['feature'].tolist()\n","\n","print(f\"Checking drift across time periods for {len(final_features)} features\")\n","\n","# Split training data into early vs late periods\n","mid_point = len(train) // 2\n","early_period = train.iloc[:mid_point]\n","late_period = train.iloc[mid_point:]\n","\n","print(f\"Early period: {len(early_period)} samples\")\n","print(f\"Late period: {len(late_period)} samples\")\n","\n","# Check drift for each feature\n","high_drift_features = []\n","drift_scores = []\n","\n","for feature in final_features:\n","    early_mean = early_period[feature].mean()\n","    late_mean = late_period[feature].mean()\n","\n","    # Calculate drift score\n","    drift = abs(early_mean - late_mean) / (abs(early_mean) + 1e-8)\n","    drift_scores.append(drift)\n","\n","    if drift > 1.0:  # High drift threshold\n","        high_drift_features.append((feature, drift))\n","\n","print(f\"\\n=== Drift Analysis ===\")\n","print(f\"Mean drift score: {np.mean(drift_scores):.4f}\")\n","print(f\"Max drift score: {np.max(drift_scores):.4f}\")\n","print(f\"Features with high drift (>1.0): {len(high_drift_features)}\")\n","\n","if len(high_drift_features) > 0:\n","    print(f\"\\nTop 5 most drifted features:\")\n","    high_drift_features.sort(key=lambda x: x[1], reverse=True)\n","    for feat, score in high_drift_features[:5]:\n","        print(f\"  {feat}: {score:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-k_Fnhpd8Qq","executionInfo":{"status":"ok","timestamp":1753395047896,"user_tz":-480,"elapsed":13975,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"1bf50f8e-0f42-429d-8afd-7998613c7c66"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Checking drift across time periods for 400 features\n","Early period: 262943 samples\n","Late period: 262943 samples\n","\n","=== Drift Analysis ===\n","Mean drift score: nan\n","Max drift score: nan\n","Features with high drift (>1.0): 217\n","\n","Top 5 most drifted features:\n","  X304: 130.4998\n","  X388: 84.3425\n","  X587_div_X588_spread_ratio: 46.9160\n","  X3_rolling_mean_50: 36.4383\n","  X258: 29.7867\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:52: RuntimeWarning: invalid value encountered in reduce\n","  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6x3t9W4Ld8Yl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQwINMJwttZo"},"outputs":[],"source":[]},{"cell_type":"code","source":["# dectecting distribution drift\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","\n","\n","# Load 400 CV-selected features\n","train = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/train_final_selected.parquet')\n","selected_features_df = pd.read_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/selected_features.csv')\n","final_features = selected_features_df['feature'].tolist()\n","\n","print(f\"Starting with {len(final_features)} CV-selected features\")\n","X = train[final_features]\n","y = train['label']\n","\n","class DistributionDriftDetector:\n","    \"\"\"\n","    Detect distribution drift between train and validation periods.\n","    \"\"\"\n","\n","    def __init__(self, drift_threshold=0.5):\n","        self.drift_threshold = drift_threshold\n","        self.drift_scores = {}\n","\n","    def calculate_ks_statistic(self, train_data, val_data):\n","        \"\"\"\n","        Calculate Kolmogorov-Smirnov statistic for distribution comparison.\n","        \"\"\"\n","        ks_stat, p_value = stats.ks_2samp(train_data, val_data)\n","        return ks_stat, p_value\n","\n","    def detect_drift(self, X_train, X_val, feature_names=None):\n","        \"\"\"\n","        Detect distribution drift for all features.\n","        \"\"\"\n","        if feature_names is None:\n","            feature_names = X_train.columns\n","\n","        drift_scores = {}\n","\n","        for feature in tqdm(feature_names, desc=\"Detecting drift\"):\n","            if feature in X_train.columns and feature in X_val.columns:\n","                train_data = X_train[feature].dropna()\n","                val_data = X_val[feature].dropna()\n","\n","                if len(train_data) > 10 and len(val_data) > 10:\n","                    ks_stat, p_value = self.calculate_ks_statistic(train_data, val_data)\n","\n","                    drift_scores[feature] = {\n","                        'ks_statistic': ks_stat,\n","                        'p_value': p_value,\n","                        'has_drift': p_value < self.drift_threshold,\n","                        'drift_severity': ks_stat\n","                    }\n","\n","        self.drift_scores = drift_scores\n","        return drift_scores\n","\n","    def get_drift_free_features(self, drift_scores):\n","        \"\"\"\n","        Get features without significant drift.\n","        \"\"\"\n","        drift_free = [feature for feature, scores in drift_scores.items()\n","                     if not scores['has_drift']]\n","        return drift_free\n","\n","    def plot_drift_analysis(self, drift_scores, top_n=20):\n","        \"\"\"\n","        Plot drift analysis results.\n","        \"\"\"\n","        # Sort by drift severity\n","        sorted_drift = sorted(drift_scores.items(),\n","                            key=lambda x: x[1]['drift_severity'], reverse=True)\n","\n","        features = [f[0] for f in sorted_drift[:top_n]]\n","        severities = [f[1]['drift_severity'] for f in sorted_drift[:top_n]]\n","        p_values = [f[1]['p_value'] for f in sorted_drift[:top_n]]\n","\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","        # Drift severity\n","        ax1.barh(range(len(features)), severities)\n","        ax1.set_yticks(range(len(features)))\n","        ax1.set_yticklabels(features)\n","        ax1.set_title('Top Features by Drift Severity')\n","        ax1.set_xlabel('KS Statistic')\n","\n","        # P-values\n","        ax2.scatter(severities, p_values, alpha=0.7)\n","        ax2.axhline(y=self.drift_threshold, color='r', linestyle='--', label=f'Threshold ({self.drift_threshold})')\n","        ax2.set_xlabel('KS Statistic')\n","        ax2.set_ylabel('P-value')\n","        ax2.set_title('Drift Severity vs P-value')\n","        ax2.legend()\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return fig\n","\n","print(\"Distribution drift detector loaded!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulNKFZiVuTUP","executionInfo":{"status":"ok","timestamp":1753396814126,"user_tz":-480,"elapsed":82774,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"d8ec314d-fbd1-4b4c-c5c8-2015cacfda0e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Starting with 400 CV-selected features\n","Distribution drift detector loaded!\n"]}]},{"cell_type":"code","source":["# forward / backward feature selection\n","\n","class ForwardBackwardSelector:\n","    \"\"\"\n","    Forward/backward feature selection with CV validation.\n","    \"\"\"\n","\n","    def __init__(self, cv_runner, min_improvement=0.001, max_features=100):\n","        self.cv_runner = cv_runner\n","        self.min_improvement = min_improvement\n","        self.max_features = max_features\n","        self.selected_features = []\n","        self.selection_history = []\n","\n","    def forward_selection(self, X, y, candidate_features):\n","        \"\"\"\n","        Forward selection: add features one by one.\n","        \"\"\"\n","        selected = []\n","        remaining = candidate_features.copy()\n","\n","        print(\"Starting forward selection...\")\n","\n","        while len(selected) < self.max_features and remaining:\n","            best_feature = None\n","            best_score = -1\n","\n","            for feature in tqdm(remaining, desc=f\"Testing {len(remaining)} features\"):\n","                # Add feature temporarily\n","                test_features = selected + [feature]\n","                X_test = X[test_features]\n","\n","                # Run CV\n","                results = self.cv_runner.run_cv(X_test, y)\n","                score = results['mean_score']\n","\n","                if score > best_score:\n","                    best_score = score\n","                    best_feature = feature\n","\n","            # Check if improvement is significant\n","            if best_feature and best_score > self.min_improvement:\n","                selected.append(best_feature)\n","                remaining.remove(best_feature)\n","\n","                self.selection_history.append({\n","                    'feature': best_feature,\n","                    'score': best_score,\n","                    'n_features': len(selected)\n","                })\n","\n","                print(f\"Added {best_feature}, score: {best_score:.4f}, n_features: {len(selected)}\")\n","            else:\n","                break\n","\n","        self.selected_features = selected\n","        return selected\n","\n","    def backward_elimination(self, X, y, initial_features):\n","        \"\"\"\n","        Backward elimination: remove features one by one.\n","        \"\"\"\n","        current_features = initial_features.copy()\n","\n","        print(\"Starting backward elimination...\")\n","\n","        while len(current_features) > 10:  # Keep at least 10 features\n","            worst_feature = None\n","            best_score = -1\n","\n","            for feature in tqdm(current_features, desc=f\"Testing removal of {len(current_features)} features\"):\n","                # Remove feature temporarily\n","                test_features = [f for f in current_features if f != feature]\n","                X_test = X[test_features]\n","\n","                # Run CV\n","                results = self.cv_runner.run_cv(X_test, y)\n","                score = results['mean_score']\n","\n","                if score > best_score:\n","                    best_score = score\n","                    worst_feature = feature\n","\n","            # Remove worst feature if it improves score\n","            if worst_feature and best_score > self.min_improvement:\n","                current_features.remove(worst_feature)\n","                print(f\"Removed {worst_feature}, score: {best_score:.4f}, n_features: {len(current_features)}\")\n","            else:\n","                break\n","\n","        return current_features\n","\n","print(\"Forward/backward selector loaded!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHCtvDZZuW83","executionInfo":{"status":"ok","timestamp":1753396822170,"user_tz":-480,"elapsed":61,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"fa497f25-463b-4259-c383-1733eacd6a6c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Forward/backward selector loaded!\n"]}]},{"cell_type":"code","source":["# regularization-based selection\n","\n","class RegularizationSelector:\n","    \"\"\"\n","    Feature selection using L1/L2 regularization.\n","    \"\"\"\n","\n","    def __init__(self, l1_ratio=0.5, max_features=100):\n","        self.l1_ratio = l1_ratio\n","        self.max_features = max_features\n","\n","    def select_with_regularization(self, X, y, cv_runner):\n","        \"\"\"\n","        Select features using regularization.\n","        \"\"\"\n","        from sklearn.linear_model import ElasticNet\n","        from sklearn.preprocessing import StandardScaler\n","\n","        # Scale features\n","        scaler = StandardScaler()\n","        X_scaled = scaler.fit_transform(X)\n","\n","        # Use ElasticNet with L1 penalty\n","        model = ElasticNet(\n","            alpha=0.01,  # Regularization strength\n","            l1_ratio=self.l1_ratio,  # L1 vs L2 ratio\n","            random_state=42,\n","            max_iter=1000\n","        )\n","\n","        # Fit model\n","        model.fit(X_scaled, y)\n","\n","        # Get feature importance (absolute coefficients)\n","        feature_importance = np.abs(model.coef_)\n","\n","        # Select features with non-zero coefficients\n","        selected_indices = np.where(feature_importance > 0)[0]\n","        selected_features = X.columns[selected_indices].tolist()\n","\n","        # Limit number of features\n","        if len(selected_features) > self.max_features:\n","            # Sort by importance and take top features\n","            feature_scores = list(zip(selected_features, feature_importance[selected_indices]))\n","            feature_scores.sort(key=lambda x: x[1], reverse=True)\n","            selected_features = [f[0] for f in feature_scores[:self.max_features]]\n","\n","        return selected_features\n","\n","print(\"Regularization selector loaded!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FrB1BKtcufP1","executionInfo":{"status":"ok","timestamp":1753396826232,"user_tz":-480,"elapsed":63,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"efe776bb-f969-4c58-e56e-e20ae205503b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Regularization selector loaded!\n"]}]},{"cell_type":"code","source":["# selection pipeline\n","\n","class ComprehensiveFeatureSelector:\n","    \"\"\"\n","    Comprehensive feature selection pipeline combining multiple strategies.\n","    \"\"\"\n","\n","    def __init__(self, cv_runner, max_features=200):\n","        self.cv_runner = cv_runner\n","        self.max_features = max_features\n","        # Remove stability_selector since we already did that\n","        self.drift_detector = DistributionDriftDetector()\n","        self.forward_backward_selector = ForwardBackwardSelector(cv_runner)\n","        self.regularization_selector = RegularizationSelector()\n","\n","        self.final_features = []\n","        self.selection_summary = {}\n","\n","    def run_comprehensive_selection(self, X, y, X_train=None, X_val=None):\n","        \"\"\"\n","        Run comprehensive feature selection pipeline.\n","        \"\"\"\n","        print(\"COMPREHENSIVE FEATURE SELECTION\")\n","\n","        # Start with provided features (your 400 CV-selected ones)\n","        starting_features = list(X.columns)\n","        print(f\"Starting with {len(starting_features)} pre-selected features\")\n","\n","        # Step 1: Distribution drift detection\n","        if X_train is not None and X_val is not None:\n","            print(\"\\n1. Distribution drift detection...\")\n","            drift_scores = self.drift_detector.detect_drift(\n","                X_train, X_val, starting_features\n","            )\n","            drift_free_features = self.drift_detector.get_drift_free_features(drift_scores)\n","            print(f\"Found {len(drift_free_features)} drift-free features\")\n","        else:\n","            drift_free_features = starting_features\n","\n","        # Step 2: Forward selection\n","        print(\"\\n2. Forward selection...\")\n","        forward_selected = self.forward_backward_selector.forward_selection(\n","            X[drift_free_features], y, drift_free_features\n","        )\n","        print(f\"Forward selection: {len(forward_selected)} features\")\n","\n","        # Step 3: Regularization-based selection\n","        print(\"\\n3. Regularization-based selection...\")\n","        reg_selected = self.regularization_selector.select_with_regularization(\n","            X[forward_selected], y, self.cv_runner\n","        )\n","        print(f\"Regularization selection: {len(reg_selected)} features\")\n","\n","        # Step 4: Final validation\n","        print(\"\\n4. Final validation...\")\n","        X_final = X[reg_selected]\n","        final_results = self.cv_runner.run_cv(X_final, y)\n","\n","        # Store results\n","        self.final_features = reg_selected\n","        self.selection_summary = {\n","            'starting_features': len(starting_features),\n","            'drift_free_features': len(drift_free_features),\n","            'forward_selected': len(forward_selected),\n","            'final_features': len(reg_selected),\n","            'final_score': final_results['mean_score'],\n","            'final_std': final_results['std_score']\n","        }\n","\n","        return reg_selected, final_results\n","\n","    def plot_selection_summary(self):\n","        \"\"\"\n","        Plot feature selection summary.\n","        \"\"\"\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n","\n","        # Selection pipeline summary\n","        stages = ['Starting', 'Drift-Free', 'Forward', 'Final']\n","        counts = [\n","            self.selection_summary['starting_features'],\n","            self.selection_summary['drift_free_features'],\n","            self.selection_summary['forward_selected'],\n","            self.selection_summary['final_features']\n","        ]\n","\n","        ax1.bar(stages, counts)\n","        ax1.set_title('Feature Count at Each Selection Stage')\n","        ax1.set_ylabel('Number of Features')\n","\n","        # Final performance\n","        ax2.bar(['Final Score'], [self.selection_summary['final_score']])\n","        ax2.set_title('Final CV Score')\n","        ax2.set_ylabel('Pearson Correlation')\n","        ax2.set_ylim(0, 1)\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return fig"],"metadata":{"id":"9R4yLGTthx-8","executionInfo":{"status":"ok","timestamp":1753396828953,"user_tz":-480,"elapsed":38,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# copying CV functions again\n","\n","class CrossValidationRunner:\n","    \"\"\"\n","    Cross-validation runner for feature selection.\n","    \"\"\"\n","\n","    def __init__(self, model_class, model_params, cv_folds=5, random_state=42):\n","        self.model_class = model_class\n","        self.model_params = model_params\n","        self.cv_folds = cv_folds\n","        self.random_state = random_state\n","        self.feature_importance = {}\n","\n","    def run_cv(self, X, y):\n","        \"\"\"\n","        Run cross-validation and return results.\n","        \"\"\"\n","        from sklearn.model_selection import KFold\n","        from sklearn.metrics import mean_squared_error\n","        import numpy as np\n","\n","        kf = KFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n","        scores = []\n","\n","        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n","            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","            # Train model\n","            model = self.model_class(**self.model_params)\n","            model.fit(X_train, y_train)\n","\n","            # Predict and score\n","            y_pred = model.predict(X_val)\n","            score = np.sqrt(mean_squared_error(y_val, y_pred))\n","            scores.append(score)\n","\n","            # Store feature importance\n","            if hasattr(model, 'feature_importances_'):\n","                self.feature_importance[fold] = dict(zip(X.columns, model.feature_importances_))\n","\n","        return {\n","            'scores': scores,\n","            'mean_score': np.mean(scores),\n","            'std_score': np.std(scores)\n","        }"],"metadata":{"id":"tNXY3VnVigJE","executionInfo":{"status":"ok","timestamp":1753396832065,"user_tz":-480,"elapsed":29,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# main\n","\n","import pandas as pd\n","import numpy as np\n","import warnings\n","from sklearn.model_selection import TimeSeriesSplit, KFold\n","from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import Lasso, Ridge\n","import lightgbm as lgb\n","import gc\n","from tqdm import tqdm\n","from scipy import stats\n","from scipy.stats import ks_2samp\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","warnings.filterwarnings('ignore')\n","\n","train = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/train_final_selected.parquet')\n","selected_features_df = pd.read_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/selected_features.csv')\n","final_features = selected_features_df['feature'].tolist()\n","\n","X = train[final_features]  # Use 400 selected features\n","y = train['label']\n","\n","print(f\"Starting with {X.shape[1]} CV-selected features\")\n","\n","# 2.5. Create CV runner (THIS WAS MISSING!)\n","cv_runner = CrossValidationRunner(\n","    model_class=lgb.LGBMRegressor,\n","    model_params={\n","        'n_estimators': 100,\n","        'learning_rate': 0.1,\n","        'max_depth': 6,\n","        'random_state': 42,\n","        'verbose': -1\n","    },\n","    cv_folds=3,  # Reduced for speed\n","    random_state=42\n",")\n","\n","# 3. Create feature selector\n","feature_selector = ComprehensiveFeatureSelector(cv_runner, max_features=200)\n","\n","# 4. Split data for drift detection\n","split_idx = int(len(X) * 0.6)\n","X_train_drift = X.iloc[:split_idx]\n","X_val_drift = X.iloc[split_idx:split_idx + int(len(X) * 0.2)]\n","\n","# 5. Run comprehensive feature selection\n","selected_features, final_results = feature_selector.run_comprehensive_selection(\n","    X, y, X_train_drift, X_val_drift\n",")\n","\n","\n","print(f\"Final features: {len(selected_features)}\")\n","print(f\"Final CV score: {final_results['mean_score']:.6f} ± {final_results['std_score']:.6f}\")\n","\n","# Save final features\n","final_features_df = pd.DataFrame({'feature': selected_features})\n","final_features_df.to_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/final_optimized_features.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"0zZq-9UPunoe","executionInfo":{"status":"error","timestamp":1753396884625,"user_tz":-480,"elapsed":50636,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"}},"outputId":"a61f6c0e-6c70-4984-9f3b-5b22501fea6f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting with 400 CV-selected features\n","COMPREHENSIVE FEATURE SELECTION\n","Starting with 400 pre-selected features\n","\n","1. Distribution drift detection...\n"]},{"output_type":"stream","name":"stderr","text":["Detecting drift: 100%|██████████| 400/400 [00:42<00:00,  9.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Found 0 drift-free features\n","\n","2. Forward selection...\n","Starting forward selection...\n","Forward selection: 0 features\n","\n","3. Regularization-based selection...\n"]},{"output_type":"error","ename":"ValueError","evalue":"at least one array or dtype is required","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-6-2354541065.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# 5. Run comprehensive feature selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m selected_features, final_results = feature_selector.run_comprehensive_selection(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_drift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_drift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m )\n","\u001b[0;32m/tmp/ipython-input-4-1089503972.py\u001b[0m in \u001b[0;36mrun_comprehensive_selection\u001b[0;34m(self, X, y, X_train, X_val)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Step 3: Regularization-based selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n3. Regularization-based selection...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         reg_selected = self.regularization_selector.select_with_regularization(\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mforward_selected\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_runner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n","\u001b[0;32m/tmp/ipython-input-3-2707859651.py\u001b[0m in \u001b[0;36mselect_with_regularization\u001b[0;34m(self, X, y, cv_runner)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Scale features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Use ElasticNet with L1 penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m         )\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdtype_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0mdtype_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpandas_requires_conversion\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;31m# Force object if any of the dtypes is an object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"]}]}]}