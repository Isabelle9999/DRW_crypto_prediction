{"cells":[{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1753401522321,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"SmC3UKMEvZM4","outputId":"ed0974cb-5fbd-4217-d021-685e5936e6ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["LightGBM trainer setup complete!\n"]}],"source":["# configurations\n","\n","import pandas as pd\n","import numpy as np\n","import lightgbm as lgb\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.metrics import make_scorer\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","import warnings\n","import pickle\n","import json\n","from datetime import datetime\n","warnings.filterwarnings('ignore')\n","\n","class LightGBMTrainer:\n","\n","    def __init__(self, cv_runner, pearson_scorer):\n","        self.cv_runner = cv_runner\n","        self.pearson_scorer = pearson_scorer\n","        self.best_params = {}\n","        self.final_models = {}\n","        self.feature_importance = {}\n","        self.training_history = {}\n","\n","    def get_winner_parameters(self):\n","\n","        param_grid = {\n","            'objective': ['regression'],  # Squared loss as per 2nd place\n","            'metric': ['rmse'],\n","            'boosting_type': ['gbdt'],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.3],  # Winners focused on this\n","            'num_leaves': [31, 50, 100, 200],  # Winners tuned this\n","            'n_estimators': [500, 1000, 2000],  # With early stopping\n","            'feature_fraction': [0.9],  # Winners kept default\n","            'bagging_fraction': [0.8],  # Winners kept default\n","            'bagging_freq': [5],\n","            'verbose': [-1],\n","            'random_state': [42],\n","            'early_stopping_rounds': [50]\n","        }\n","\n","        return param_grid\n","\n","    def optimize_hyperparameters(self, X, y, max_combinations=20):\n","        \"\"\"\n","        Optimize hyperparameters using time series CV.\n","        \"\"\"\n","\n","        param_grid = self.get_winner_parameters()\n","        param_combinations = list(ParameterGrid(param_grid))\n","\n","        # Limit combinations to avoid excessive computation\n","        if len(param_combinations) \u003e max_combinations:\n","            # Sample most promising combinations\n","            param_combinations = np.random.choice(\n","                param_combinations, max_combinations, replace=False\n","            ).tolist()\n","\n","        best_score = -1\n","        best_params = {}\n","        results = []\n","\n","        print(f\"Testing {len(param_combinations)} parameter combinations...\")\n","\n","        for i, params in enumerate(tqdm(param_combinations, desc=\"Parameter tuning\")):\n","            try:\n","                # Run CV with these parameters\n","                cv_results = self.cv_runner.run_cv(X, y, params)\n","                score = cv_results['mean_score']\n","\n","                results.append({\n","                    'params': params,\n","                    'score': score,\n","                    'std_score': cv_results['std_score']\n","                })\n","\n","                if score \u003e best_score:\n","                    best_score = score\n","                    best_params = params.copy()\n","                    print(f\"New best score: {score:.4f} with params: {params}\")\n","\n","            except Exception as e:\n","                print(f\"Error with params {params}: {e}\")\n","                continue\n","\n","        # Sort results by score\n","        results.sort(key=lambda x: x['score'], reverse=True)\n","\n","        self.best_params = best_params\n","        self.training_history['hyperparameter_results'] = results\n","\n","        print(f\"\\nBest parameters: {best_params}\")\n","        print(f\"Best CV score: {best_score:.4f}\")\n","\n","        return best_params, results\n","\n","print(\"LightGBM trainer setup complete!\")"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753401522344,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"Vz0yHD7avcbZ","outputId":"c11b1945-7644-47bf-ed50-ae398a3f57ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Market regime models setup complete!\n"]}],"source":["# market regime models\n","\n","class MarketRegimeModels:\n","    \"\"\"\n","    Train separate models for different market regimes.\n","    \"\"\"\n","\n","    def __init__(self, cv_runner, best_params):\n","        self.cv_runner = cv_runner\n","        self.best_params = best_params\n","        self.regime_models = {}\n","        self.regime_performance = {}\n","\n","    def train_regime_models(self, X, y, regime_labels):\n","        \"\"\"\n","        Train separate models for each market regime.\n","        \"\"\"\n","        print(\"=== MARKET REGIME MODELS (9th Place Strategy) ===\")\n","\n","        # Identify regimes\n","        unique_regimes = regime_labels.unique()\n","        print(f\"Found regimes: {unique_regimes}\")\n","\n","        for regime in unique_regimes:\n","            print(f\"\\nTraining model for {regime} regime...\")\n","\n","            # Filter data for this regime\n","            regime_mask = regime_labels == regime\n","            X_regime = X[regime_mask]\n","            y_regime = y[regime_mask]\n","\n","            if len(X_regime) \u003c 1000:  # Skip if too few samples\n","                print(f\"Skipping {regime} regime - too few samples ({len(X_regime)})\")\n","                continue\n","\n","            print(f\"Regime {regime}: {len(X_regime)} samples\")\n","\n","            # Train model for this regime\n","            model = lgb.LGBMRegressor(**self.best_params)\n","            model.fit(X_regime, y_regime)\n","\n","            # Store model\n","            self.regime_models[regime] = model\n","\n","            # Evaluate performance\n","            y_pred = model.predict(X_regime)\n","            score = np.corrcoef(y_regime, y_pred)[0, 1]\n","            self.regime_performance[regime] = score\n","\n","            print(f\"Regime {regime} performance: {score:.4f}\")\n","\n","        return self.regime_models\n","\n","    def predict_with_regime_models(self, X, regime_labels):\n","        \"\"\"\n","        Make predictions using regime-specific models.\n","        \"\"\"\n","        predictions = np.zeros(len(X))\n","        regime_counts = {}\n","\n","        for regime, model in self.regime_models.items():\n","            regime_mask = regime_labels == regime\n","            if regime_mask.sum() \u003e 0:\n","                regime_pred = model.predict(X[regime_mask])\n","                predictions[regime_mask] = regime_pred\n","                regime_counts[regime] = regime_mask.sum()\n","\n","        print(f\"Predictions by regime: {regime_counts}\")\n","        return predictions\n","\n","print(\"Market regime models setup complete!\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1753401522377,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"4urKsU_KvnY8","outputId":"a4015542-5aa3-46f5-d789-359eae98b414"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final model trainer setup complete!\n"]}],"source":["# model training\n","\n","class FinalModelTrainer:\n","    \"\"\"\n","    Train final model on all available data.\n","    \"\"\"\n","\n","    def __init__(self, best_params):\n","        self.best_params = best_params\n","        self.final_model = None\n","        self.feature_importance = {}\n","        self.training_metrics = {}\n","\n","    def train_final_model(self, X, y, save_path=None):\n","        \"\"\"\n","        Train final model on all available data\n","        \"\"\"\n","\n","        print(f\"Training on {len(X)} samples with {X.shape[1]} features\")\n","\n","        # Train model\n","        self.final_model = lgb.LGBMRegressor(**self.best_params)\n","        self.final_model.fit(X, y)\n","\n","        # Get feature importance\n","        if hasattr(self.final_model, 'feature_importances_'):\n","            self.feature_importance = dict(zip(X.columns, self.final_model.feature_importances_))\n","\n","        # Calculate training metrics\n","        y_pred = self.final_model.predict(X)\n","        self.training_metrics = {\n","            'pearson_correlation': np.corrcoef(y, y_pred)[0, 1],\n","            'rmse': np.sqrt(np.mean((y - y_pred) ** 2)),\n","            'mae': np.mean(np.abs(y - y_pred))\n","        }\n","\n","        print(f\"Training metrics:\")\n","        for metric, value in self.training_metrics.items():\n","            print(f\"  {metric}: {value:.4f}\")\n","\n","        # Save model\n","        if save_path:\n","            self.save_model(save_path)\n","\n","        return self.final_model\n","\n","    def save_model(self, save_path):\n","        \"\"\"\n","        Save model and metadata.\n","        \"\"\"\n","        model_data = {\n","            'model': self.final_model,\n","            'feature_importance': self.feature_importance,\n","            'training_metrics': self.training_metrics,\n","            'best_params': self.best_params,\n","            'timestamp': datetime.now().isoformat()\n","        }\n","\n","        with open(save_path, 'wb') as f:\n","            pickle.dump(model_data, f)\n","\n","        print(f\"Model saved to {save_path}\")\n","\n","    def load_model(self, load_path):\n","        \"\"\"\n","        Load saved model.\n","        \"\"\"\n","        with open(load_path, 'rb') as f:\n","            model_data = pickle.load(f)\n","\n","        self.final_model = model_data['model']\n","        self.feature_importance = model_data['feature_importance']\n","        self.training_metrics = model_data['training_metrics']\n","        self.best_params = model_data['best_params']\n","\n","        print(f\"Model loaded from {load_path}\")\n","\n","print(\"Final model trainer setup complete!\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753401522385,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"HdvEeDdnvpxv","outputId":"756bac0e-dac9-48be-9fd1-b89ea9f1d44e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model diagnostics setup complete!\n"]}],"source":["# model diagonostics\n","\n","class ModelDiagnostics:\n","    \"\"\"\n","    Comprehensive model diagnostics and analysis.\n","    \"\"\"\n","\n","    def __init__(self, final_model, feature_importance, training_metrics):\n","        self.final_model = final_model\n","        self.feature_importance = feature_importance\n","        self.training_metrics = training_metrics\n","\n","    def plot_feature_importance(self, top_n=20):\n","        \"\"\"\n","        Plot feature importance analysis.\n","        \"\"\"\n","        if not self.feature_importance:\n","            print(\"No feature importance available\")\n","            return\n","\n","        # Sort features by importance\n","        sorted_features = sorted(self.feature_importance.items(),\n","                               key=lambda x: x[1], reverse=True)\n","\n","        features = [f[0] for f in sorted_features[:top_n]]\n","        importances = [f[1] for f in sorted_features[:top_n]]\n","\n","        plt.figure(figsize=(12, 8))\n","        plt.barh(range(len(features)), importances)\n","        plt.yticks(range(len(features)), features)\n","        plt.xlabel('Feature Importance')\n","        plt.title('Top Feature Importance')\n","        plt.gca().invert_yaxis()\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return sorted_features[:top_n]\n","\n","    def plot_prediction_analysis(self, y_true, y_pred):\n","        \"\"\"\n","        Plot prediction vs actual analysis.\n","        \"\"\"\n","        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","\n","        # Scatter plot\n","        axes[0, 0].scatter(y_true, y_pred, alpha=0.5)\n","        axes[0, 0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n","        axes[0, 0].set_xlabel('Actual')\n","        axes[0, 0].set_ylabel('Predicted')\n","        axes[0, 0].set_title('Predictions vs Actual')\n","\n","        # Residual plot\n","        residuals = y_true - y_pred\n","        axes[0, 1].scatter(y_pred, residuals, alpha=0.5)\n","        axes[0, 1].axhline(y=0, color='r', linestyle='--')\n","        axes[0, 1].set_xlabel('Predicted')\n","        axes[0, 1].set_ylabel('Residuals')\n","        axes[0, 1].set_title('Residual Plot')\n","\n","        # Distribution comparison\n","        axes[1, 0].hist(y_true, alpha=0.7, label='Actual', bins=30)\n","        axes[1, 0].hist(y_pred, alpha=0.7, label='Predicted', bins=30)\n","        axes[1, 0].set_xlabel('Value')\n","        axes[1, 0].set_ylabel('Frequency')\n","        axes[1, 0].set_title('Distribution Comparison')\n","        axes[1, 0].legend()\n","\n","        # Residual distribution\n","        axes[1, 1].hist(residuals, bins=30)\n","        axes[1, 1].set_xlabel('Residual')\n","        axes[1, 1].set_ylabel('Frequency')\n","        axes[1, 1].set_title('Residual Distribution')\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return fig\n","\n","    def analyze_regime_performance(self, y_true, y_pred, regime_labels):\n","        \"\"\"\n","        Analyze performance by market regime.\n","        \"\"\"\n","        regime_performance = {}\n","\n","        for regime in regime_labels.unique():\n","            mask = regime_labels == regime\n","            if mask.sum() \u003e 10:\n","                regime_true = y_true[mask]\n","                regime_pred = y_pred[mask]\n","                corr = np.corrcoef(regime_true, regime_pred)[0, 1]\n","                rmse = np.sqrt(np.mean((regime_true - regime_pred) ** 2))\n","\n","                regime_performance[regime] = {\n","                    'correlation': corr,\n","                    'rmse': rmse,\n","                    'samples': mask.sum()\n","                }\n","\n","        # Plot regime performance\n","        regimes = list(regime_performance.keys())\n","        correlations = [regime_performance[r]['correlation'] for r in regimes]\n","        samples = [regime_performance[r]['samples'] for r in regimes]\n","\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n","\n","        ax1.bar(regimes, correlations)\n","        ax1.set_title('Performance by Market Regime')\n","        ax1.set_ylabel('Pearson Correlation')\n","        ax1.tick_params(axis='x', rotation=45)\n","\n","        ax2.bar(regimes, samples)\n","        ax2.set_title('Samples by Market Regime')\n","        ax2.set_ylabel('Number of Samples')\n","        ax2.tick_params(axis='x', rotation=45)\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        return regime_performance\n","\n","print(\"Model diagnostics setup complete!\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1753401522392,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"vF7tD7Nbvtcr","outputId":"bbbb16bd-c470-4d70-9942-fb3947fa3437"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test data processor setup complete!\n"]}],"source":["# test data processing \u0026 predictions\n","\n","class TestDataProcessor:\n","    \"\"\"\n","    Process test data and generate predictions.\n","    \"\"\"\n","\n","    def __init__(self, final_model, feature_importance):\n","        self.final_model = final_model\n","        self.feature_importance = feature_importance\n","\n","    def process_test_data(self, test_data, feature_engineering_pipeline):\n","        \"\"\"\n","        Apply same preprocessing to test data.\n","        \"\"\"\n","        print(\"TEST DATA PROCESSING\")\n","\n","        # Apply same feature engineering\n","        # This should include:\n","        # - HMA features\n","        # - Market regime features\n","        # - Rolling statistics\n","        # - Cross-feature interactions\n","\n","        processed_test = test_data.copy()\n","\n","        # Add your feature engineering steps here\n","        # (This will depend on your specific pipeline)\n","\n","        return processed_test\n","\n","    def generate_predictions(self, processed_test, regime_models=None, regime_labels=None):\n","        \"\"\"\n","        Generate predictions for test data.\n","        \"\"\"\n","        print(\"GENERATING PREDICTIONS\")\n","\n","        if regime_models and regime_labels is not None:\n","            # Use regime-specific models (9th place strategy)\n","            predictions = np.zeros(len(processed_test))\n","\n","            for regime, model in regime_models.items():\n","                regime_mask = regime_labels == regime\n","                if regime_mask.sum() \u003e 0:\n","                    regime_pred = model.predict(processed_test[regime_mask])\n","                    predictions[regime_mask] = regime_pred\n","\n","            print(f\"Generated predictions using regime models\")\n","        else:\n","            # Use single final model\n","            predictions = self.final_model.predict(processed_test)\n","            print(f\"Generated predictions using final model\")\n","\n","        return predictions\n","\n","    def create_submission(self, predictions, sample_submission_path, output_path):\n","        \"\"\"\n","        Create submission file.\n","        \"\"\"\n","        # Load sample submission\n","        sample_sub = pd.read_csv(sample_submission_path)\n","\n","        # Update predictions\n","        sample_sub['label'] = predictions\n","\n","        # Save submission\n","        sample_sub.to_csv(output_path, index=False)\n","        print(f\"Submission saved to {output_path}\")\n","\n","        return sample_sub\n","\n","print(\"Test data processor setup complete!\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3002,"status":"ok","timestamp":1753401525394,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"dUaHY0J6udu1","outputId":"4a65e557-6586-4136-84ef-7ead5ad32b8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Loaded data shape: (525886, 402)\n","Selected features: 400\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load final selected features\n","train = pd.read_parquet('/content/drive/MyDrive/DRW Crypto Market Prediction/train_final_selected.parquet')\n","selected_features_df = pd.read_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/selected_features.csv')\n","feature_names = selected_features_df['feature'].tolist()\n","\n","print(f\"Loaded data shape: {train.shape}\")\n","print(f\"Selected features: {len(feature_names)}\")\n","\n","# Prepare features and target\n","X = train[feature_names]\n","y = train['label']  # Changed from 'target' to 'label'"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4352,"status":"ok","timestamp":1753401529753,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"7xSCKQc91vOX","outputId":"e7d5c1de-ebf4-4f62-e45a-e50bed6d97d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n","Requirement already satisfied: alembic\u003e=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n","Requirement already satisfied: sqlalchemy\u003e=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (1.1.3)\n","Requirement already satisfied: typing-extensions\u003e=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic\u003e=1.5.0-\u003eoptuna) (4.14.1)\n","Requirement already satisfied: greenlet\u003e=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy\u003e=1.4.2-\u003eoptuna) (3.2.3)\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753401529758,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"pFWQ2xyywSo7"},"outputs":[],"source":["# Core data science libraries\n","import pandas as pd\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Sklearn imports\n","from sklearn.model_selection import cross_val_score, StratifiedKFold, TimeSeriesSplit\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","# LightGBM\n","import lightgbm as lgb\n","\n","# Optimization\n","from scipy.stats import pearsonr\n","from scipy.optimize import minimize\n","import optuna\n","\n","# Plotting\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","plt.style.use('seaborn-v0_8')\n","\n","# System and utilities\n","import gc\n","import os\n","import pickle\n","import joblib\n","from datetime import datetime\n","import time\n","from tqdm import tqdm\n","\n","# Statistics\n","from scipy import stats\n","from scipy.stats import spearmanr\n","\n","# Additional utilities\n","import itertools\n","from collections import defaultdict\n","import json\n","\n","# Memory optimization\n","import psutil\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1753401529768,"user":{"displayName":"Isabelle Lu","userId":"08270117842965788156"},"user_tz":-480},"id":"Xlls1CH0wsgp","outputId":"e6a75ae1-75c3-4e6e-e487-91eaaed7b06f"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Fixed CV runner created with proper early stopping handling\n"]}],"source":["# Complete CrossValidationRunner with hyperparameter fix\n","class CrossValidationRunner:\n","    def __init__(self, n_splits=5, test_size=0.2, gap=100, scorer=None):\n","        self.n_splits = n_splits\n","        self.test_size = test_size\n","        self.gap = gap\n","        self.scorer = scorer or pearson_scorer\n","\n","    def split(self, X, y=None):\n","        n_samples = len(X)\n","        test_size = int(n_samples * self.test_size)\n","\n","        for i in range(self.n_splits):\n","            split_point = n_samples - (self.n_splits - i) * test_size\n","            if split_point \u003c= 0:\n","                continue\n","\n","            train_end = split_point - self.gap\n","            test_start = split_point\n","\n","            if train_end \u003c= 0 or test_start \u003e= n_samples:\n","                continue\n","\n","            train_indices = list(range(0, train_end))\n","            test_indices = list(range(test_start, min(test_start + test_size, n_samples)))\n","\n","            yield train_indices, test_indices\n","\n","    def run_cv(self, X, y, model_params):\n","        \"\"\"Run cross-validation and return scores\"\"\"\n","        scores = []\n","\n","        for train_idx, val_idx in self.split(X, y):\n","            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n","            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n","\n","            # FIXED: Handle early_stopping_rounds properly\n","            model_params_cv = model_params.copy()\n","\n","            if 'early_stopping_rounds' in model_params_cv:\n","                # Remove early stopping for CV (it needs eval_set which complicates things)\n","                early_stopping = model_params_cv.pop('early_stopping_rounds')\n","                model = lgb.LGBMRegressor(**model_params_cv)\n","                model.fit(X_train, y_train)\n","            else:\n","                model = lgb.LGBMRegressor(**model_params_cv)\n","                model.fit(X_train, y_train)\n","\n","            # Predict and score\n","            y_pred = model.predict(X_val)\n","            score = self.scorer(y_val, y_pred)\n","            scores.append(score)\n","\n","        return {\n","            'scores': scores,\n","            'mean_score': np.mean(scores),\n","            'std_score': np.std(scores)\n","        }\n","\n","# Define pearson_scorer function\n","def pearson_scorer(y_true, y_pred):\n","    \"\"\"Pearson correlation scorer\"\"\"\n","    from scipy.stats import pearsonr\n","    corr, _ = pearsonr(y_true, y_pred)\n","    return corr if not np.isnan(corr) else 0.0\n","\n","# Create the CV runner\n","cv_runner = CrossValidationRunner(n_splits=5, test_size=0.1, gap=100, scorer=pearson_scorer)\n","print(\" Fixed CV runner created with proper early stopping handling\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ze-5t5DAvxDG"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating balanced regime labels...\n","Created balanced regime labels from target volatility\n","Data shape: (525886, 400)\n","Target shape: (525886,)\n","Regime distribution:\n","label\n","STABLE      131486\n","LOW_VOL     131467\n","EXTREME     131467\n","HIGH_VOL    131466\n","Name: count, dtype: int64\n","\n","Initializing trainers...\n","\n"," 1. Hyperparameter optimization\n","Testing 20 parameter combinations...\n"]},{"name":"stderr","output_type":"stream","text":["Parameter tuning:   5%|▌         | 1/20 [04:29\u003c1:25:11, 269.04s/it]"]},{"name":"stdout","output_type":"stream","text":["New best score: 0.0446 with params: {'bagging_fraction': 0.8, 'bagging_freq': 5, 'boosting_type': 'gbdt', 'early_stopping_rounds': 50, 'feature_fraction': 0.9, 'learning_rate': 0.1, 'metric': 'rmse', 'n_estimators': 500, 'num_leaves': 50, 'objective': 'regression', 'random_state': 42, 'verbose': -1}\n"]},{"name":"stderr","output_type":"stream","text":["Parameter tuning:  30%|███       | 6/20 [57:13\u003c2:08:21, 550.08s/it]"]},{"name":"stdout","output_type":"stream","text":["New best score: 0.0488 with params: {'bagging_fraction': 0.8, 'bagging_freq': 5, 'boosting_type': 'gbdt', 'early_stopping_rounds': 50, 'feature_fraction': 0.9, 'learning_rate': 0.01, 'metric': 'rmse', 'n_estimators': 500, 'num_leaves': 50, 'objective': 'regression', 'random_state': 42, 'verbose': -1}\n"]}],"source":["# main\n","\n","\n","# 3. Create balanced regime labels\n","print(\"Creating balanced regime labels...\")\n","\n","# Better regime creation using quantiles for balance\n","vol_col = y.rolling(20).std()\n","regime_labels = pd.qcut(vol_col.dropna(), q=4, labels=['LOW_VOL', 'STABLE', 'HIGH_VOL', 'EXTREME'])\n","\n","# Extend to match original length (fill NaN with most common)\n","regime_labels = regime_labels.reindex(y.index).fillna('STABLE')\n","print(\"Created balanced regime labels from target volatility\")\n","\n","print(f\"Data shape: {X.shape}\")\n","print(f\"Target shape: {y.shape}\")\n","print(f\"Regime distribution:\\n{regime_labels.value_counts()}\")\n","\n","# 4. Initialize trainers\n","print(\"\\nInitializing trainers...\")\n","trainer = LightGBMTrainer(cv_runner, pearson_scorer)\n","\n","# 5. Hyperparameter optimization\n","print(\"\\n 1. Hyperparameter optimization\")\n","best_params, hp_results = trainer.optimize_hyperparameters(X, y, max_combinations=20)\n","print(f\"Best parameters found: {best_params}\")\n","\n","# 6. Market regime models\n","if regime_labels is not None:\n","    print(\"\\n 2. Training market regime models\")\n","    regime_trainer = MarketRegimeModels(cv_runner, best_params)\n","    regime_models = regime_trainer.train_regime_models(X, y, regime_labels)\n","    print(f\"Trained {len(regime_models)} regime-specific models\")\n","else:\n","    regime_models = None\n","    print(\"Skipping regime models - no regime labels available\")\n","\n","# 7. Final model training\n","print(\"\\n 3. Training final model\")\n","final_trainer = FinalModelTrainer(best_params)\n","final_model = final_trainer.train_final_model(\n","    X, y,\n","    save_path='/content/drive/MyDrive/DRW Crypto Market Prediction/final_model.pkl'\n",")\n","print(f\"Final model trained with correlation: {final_trainer.training_metrics.get('pearson_correlation', 'N/A'):.4f}\")\n","\n","# 8. Model diagnostics\n","print(\"\\n 4. Model diagnostics\")\n","diagnostics = ModelDiagnostics(\n","    final_trainer.final_model,\n","    final_trainer.feature_importance,\n","    final_trainer.training_metrics\n",")\n","\n","# Plot feature importance\n","print(\"Generating feature importance plot...\")\n","top_features = diagnostics.plot_feature_importance(top_n=20)\n","\n","# Plot prediction analysis\n","print(\"Generating prediction analysis...\")\n","y_pred = final_trainer.final_model.predict(X)\n","diagnostics.plot_prediction_analysis(y, y_pred)\n","\n","# Regime performance analysis\n","if regime_labels is not None:\n","    print(\"Analyzing regime performance...\")\n","    regime_perf = diagnostics.analyze_regime_performance(y, y_pred, regime_labels)\n","\n","# 9. Save results\n","print(\"\\n=== 5. Saving results ===\")\n","# Save feature importance\n","feature_importance_df = pd.DataFrame({\n","    'feature': [f[0] for f in top_features],\n","    'importance': [f[1] for f in top_features]\n","})\n","feature_importance_df.to_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/feature_importance.csv', index=False)\n","\n","# Save predictions\n","predictions_df = pd.DataFrame({\n","    'time_id': train['time_id'],\n","    'actual': y,\n","    'predicted': y_pred\n","})\n","predictions_df.to_csv('/content/drive/MyDrive/DRW Crypto Market Prediction/training_predictions.csv', index=False)\n","\n","print(\"\\n=== TRAINING COMPLETE ===\")\n","print(f\" Best parameters: {best_params}\")\n","print(f\" Training correlation: {final_trainer.training_metrics.get('pearson_correlation', 'N/A'):.4f}\")\n","print(f\" Top 5 features: {[f[0] for f in top_features[:5]]}\")\n","print(f\" Model saved to: final_model.pkl\")\n","print(f\" Results saved to Google Drive\")\n","\n","# Memory cleanup\n","del X, y, train\n","gc.collect()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP8Ct4qjzll479dndIGqxd3","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}